# Comparative Analysis of Programming Language Conversion Using Transformer-Based Models (Java â†’ Python)

Author: Prashant Sharma

Degree: M.Sc. Computer Science   

Project Type: Research Dissertation 

Focus Area: AI-Based Code Translation & Evaluation

# ğŸ“Œ Project Overview

This project presents a comparative study of transformer-based models for automated Java â†’ Python code translation.
It introduces a fully automated evaluation testbed and proposes a Hybrid Transformer Model to improve translation accuracy, syntax correctness, and logical reliability.

The study evaluates multiple pre-trained models under uniform test conditions to identify the most effective approach for cross-language code conversion.


# â“ Problem Statement

Software modernization and platform migration demand accurate code conversion

Manual rewriting is:

âŒ Time-consuming

âŒ Error-prone

âŒ Expensive

Traditional conversion tools fail on:

Complex logic

Large programs

Edge cases

Transformer-based models show promise but:

Sometimes generate incorrect or non-executable code

Lack clear comparative evaluation

# ğŸ¯ Objectives

Develop an automated testbed to fairly evaluate transformer models

Compare models across:

Accuracy

Syntax correctness

Execution success

Performance (latency)

Design a Hybrid Transformer Model to improve translation quality

Identify the best-performing model for Java â†’ Python conversion

# ğŸ¤– Models Evaluated

| Model            | Strengths                       | Limitations              |
| ---------------- | ------------------------------- | ------------------------ |
| **CodeT5**       | Strong semantic understanding   | Poor syntax accuracy     |
| **CodeGen**      | Fast generation                 | Weak logical correctness |
| **Gemini**       | High accuracy, strong reasoning | Cloud dependency         |
| **Hybrid Model** | Best logical clarity            | High execution time      |

# ğŸ§  Hybrid Model Architecture (CodeT5 + StarCoder)
ğŸ”¹ Stage 1 â€“ Code Analysis (CodeT5)

Generates a natural-language explanation of Java code

Captures:

Program intent

Conditions

Expected behavior

Acts as an intermediate logical representation

ğŸ”¹ Stage 2 â€“ Code Translation (StarCoder)

Uses:

Original Java code

Generated explanation

Produces logically improved Python code

ğŸ”¹ Post-Processing

Removes:

Markdown

Extra comments

Descriptive text

Outputs clean, executable Python code


# ğŸ—ï¸ System Architecture
â”œâ”€â”€ input_programs

â”œâ”€â”€ models

â”œâ”€â”€ translated

â”œâ”€â”€ references

â”œâ”€â”€ evaluators

â”œâ”€â”€ results

â””â”€â”€ main.py

# ğŸ› ï¸ Implementation Tools & Technologies

Python â€“ Core automation & execution

Hugging Face Transformers â€“ CodeT5, CodeGen, StarCoder

Gemini API â€“ Cloud-based translation

JSON â€“ Logs, metrics, structured outputs

Validators â€“ Syntax checking

Matplotlib â€“ Performance visualization

GitHub & PyCharm â€“ Development & version control

# ğŸ§ª Evaluation Metrics

BLEU Score â€“ Translation quality

Syntax Success Rate â€“ Executable correctness

Accuracy (Pass Rate) â€“ Functional correctness

Execution Time â€“ Performance efficiency

# ğŸ“Š Results & Comparison (Key Findings)
ğŸ”¹ Accuracy & Syntax

Gemini leads in: Accuracy, Syntax correctness, Execution reliability

Hybrid Model performs well but is slow

CodeT5 fails in syntax generation

CodeGen produces syntactically valid but semantically weak code
![accuracy_pass_rate.png](results/accuracy_pass_rate.png)
![bleu_quality.png](results/bleu_quality.png)
![combined_graph.png](results/combined_graph.png)
![performance_time.png](results/performance_time.png)
![syntax_success.png](results/syntax_success.png)
ğŸ”¹ Performance Summary

| Model   | Accuracy (%) | Syntax (%) | BLEU      | Time (s) |
| ------- | ------------ | ---------- | --------- | -------- |
| Gemini  | **16.11**    | **88.88**  | **45.93** | **5.08** |
| Hybrid  | 11.11        | 88.88      | 46.56     | 89.93    |
| CodeGen | 0.00         | 88.88      | 11.66     | 18.57    |
| CodeT5  | 0.00         | 0.00       | 0.00      | 13.21    |


# âœ… Conclusion

Built a fully automated Java â†’ Python translation testbed

Conducted fair and systematic evaluation of transformer models

Demonstrated that:

Gemini performs best overall

Hybrid Model improves logical accuracy without retraining

The testbed is:

Reusable

Extendable

Suitable for future research

# ğŸ”® Future Work

Fine-tuning models on Javaâ€“Python datasets

Multi-language code translation support

Advanced metrics:

CodeBLEU

AST similarity

Enhanced hybrid reasoning pipelines

Web-based UI for:

Upload

Translate

Visualize

Standardized benchmark datasets

Smarter test-case generation using LLMs & symbolic execution